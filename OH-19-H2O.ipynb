{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OH-19\n",
    "#### Favio Vázquez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The problem: Customer Churn\n",
    "\n",
    "![](https://www.insideselfstorage.com/sites/insideselfstorage.com/files/styles/article_featured_retina/public/Sad-Customer-Service.jpg?itok=S9sd0R3T)\n",
    "Credit:https://www.insideselfstorage.com/customer-service/7-deadly-customer-service-situations-self-storage-and-how-handle-them\n",
    "\n",
    "Customer churn is defined as when customers or subscribers discontinue doing business with a firm or service.\n",
    "\n",
    "Each row represents a customer, each column contains customer’s attributes.\n",
    "\n",
    "The data set includes information about:\n",
    "\n",
    "- Customers who left within the last month – the column is called **Churn**\n",
    "- Services that each customer has signed up for – phone, multiple lines, internet, online security, online backup, device protection, tech support, and streaming TV and movies\n",
    "- Customer account information – how long they’ve been a customer, contract, payment method, paperless billing, monthly charges, and total charges\n",
    "- Demographic info about customers – gender, age range, and if they have partners and dependents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand the business context and problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before spending time trying to solve a business problem, we have to be sure that we have a problem. For that we need to have meetings with the people close to the business problem and the steakholders. \n",
    "\n",
    "We had two meetings, one with HR and the other with the main excecutives. This is what we heard:\n",
    "\n",
    "- Curstomers are leaving but we don't know why.\n",
    "- We have 1 month of data for customers where we know which ones stayed and which ones left.\n",
    "- The customer churn can't surpass 15% per year due to our calculations.\n",
    "- We don't know the financial impact on losing a customer\n",
    "- We can give a voucher for \\$500 for customers identified as churn.\n",
    "- The estimated life time value for a customer is \\$7500."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After those meetings we have to check the existing data in the company and find useful information in it. Let's assume we did it and after a data integration process we created a comprehensive dataset for our customers and their information. Remember that we are working with a telco company. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datatable as dt\n",
    "from datatable import f, min, max, mean\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import scipy.stats as stats\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dt.fread(\"data/churn-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The colour signifies the datatype where red denotes string, green denotes int and blue stands for float."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many customers have left? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[f.Churn == \"Yes\", dt.count()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1869/7043"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1869 customers have left, that means 26% of our customers. So if we remember the metrics from the business we have a problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How much money have we lost due to the loss of customers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:, dt.count(), dt.by(dt.f.Churn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[dt.f.Churn == 'Yes', 'TotalCharges'].sum1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have lost $2.862.926 due to customer churn. So let's try to solve this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas = df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnostic_plots(df_pandas, variable):\n",
    "    \n",
    "    plt.figure(figsize=(20, 9))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    sns.histplot(data = df_pandas, x=variable, bins=30, kde=True)\n",
    "    plt.title('Histogram')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    stats.probplot(df_pandas[variable], dist=\"norm\", plot=plt)\n",
    "    plt.ylabel('RM quantiles')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    sns.boxplot(x=df_pandas[variable])\n",
    "    plt.title('Boxplot')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns=df_pandas.select_dtypes(include=[\"number\"]).columns\n",
    "num_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in num_columns:\n",
    "    diagnostic_plots(df_pandas,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_pandas.drop(\"SeniorCitizen\",axis=1),hue=\"Churn\",aspect=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_pandas, x=\"Churn\")\n",
    "fig.update_layout(width=700, height=500, bargap=0.1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_pandas, x=\"Churn\", color=\"SeniorCitizen\")\n",
    "fig.update_layout(width=700, height=500, bargap=0.1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_pandas, x=\"Churn\", color=\"OnlineSecurity\", barmode=\"group\")\n",
    "fig.update_layout(width=700, height=500, bargap=0.1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(df_pandas, x='Churn', y = 'tenure')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.kdeplot(df_pandas.MonthlyCharges[(df_pandas[\"Churn\"] == 'No') ],\n",
    "                color=\"Red\", shade = True);\n",
    "ax = sns.kdeplot(df_pandas.MonthlyCharges[(df_pandas[\"Churn\"] == 'Yes') ],\n",
    "                ax =ax, color=\"Blue\", shade= True);\n",
    "ax.legend([\"Not Churn\",\"Churn\"],loc='upper right');\n",
    "ax.set_ylabel('Density');\n",
    "ax.set_xlabel('Monthly Charges');\n",
    "ax.set_title('Distribution of monthly charges by churn');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_pandas.apply(lambda x: pd.factorize(x)[0]).corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "heat = go.Heatmap(\n",
    "    z=corr.mask(mask),\n",
    "    x=corr.columns,\n",
    "    y=corr.columns,\n",
    "    colorscale=px.colors.diverging.RdBu,\n",
    "    zmin=-1,\n",
    "    zmax=1\n",
    ")\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "\n",
    "fig.update_xaxes(side=\"bottom\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text='Heatmap', \n",
    "    title_x=0.5, \n",
    "    width=1000, \n",
    "    height=1000,\n",
    "    xaxis_showgrid=False,\n",
    "    yaxis_showgrid=False,\n",
    "    xaxis_zeroline=False,\n",
    "    yaxis_zeroline=False,\n",
    "    yaxis_autorange='reversed',\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig=go.Figure(data=[heat])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check this great source for learning more about datatable by my friend Rohan Rao:\n",
    "\n",
    "https://github.com/vopani/datatableton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.stypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## missing values\n",
    "dt.math.isna(df).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only have 11 missing values in the TotalCharges column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Delete missing rows\n",
    "df = df[dt.rowall(dt.f[:] != None), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete customerID\n",
    "del df[:, \"customerID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enconde Churn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df[:, 'Churn'] = dt.Frame(le.fit_transform(np.ravel(df[:, 'Churn'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for OHE\n",
    "def ohe_columns(columns,df):\n",
    "    df_work = df.copy()\n",
    "    for column in columns:\n",
    "        df_ohe = dt.str.split_into_nhot(df_work[column])\n",
    "        df_ohe.names = [f'{column}_{col}' for col in df_ohe.names]\n",
    "        df_work.cbind(df_ohe)\n",
    "    return df_work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select categorical columns\n",
    "categorical_columns = df[:, str].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get final df after OHE\n",
    "df_final = ohe_columns(categorical_columns,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete orignal columns\n",
    "del df_final[:, categorical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(\"churn_data_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/churn_data_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. H2O AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.automl import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = h2o.import_file(\"data/churn_data_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = dataset.split_frame([0.8], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train:%d test:%d\" % (train.nrows, test.nrows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify predictors and response\n",
    "x = train.columns\n",
    "y = \"Churn\"\n",
    "x.remove(y)\n",
    "\n",
    "# For binary classification, response should be a factor\n",
    "train[y] = train[y].asfactor()\n",
    "test[y] = test[y].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml = H2OAutoML(max_runtime_secs = 900, \n",
    "                max_models = 25,  \n",
    "                seed = 42, \n",
    "                project_name='classification_1',\n",
    "                sort_metric = \"AUC\")\n",
    "\n",
    "%time aml.train(x = x, y = y, training_frame = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = aml.leaderboard\n",
    "lb.head(rows = lb.nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml.leader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml.leader.model_performance(test_data=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml.leader.model_performance(test_data=test).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aml.explain(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml.leader.model_performance(test_data=test).confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This confusion matrix is on the test set which includes 20% of our data (1400 rows) We have 211 True Positives (15%) — these are the customers for which we will be able to extend the lifetime value. If we wouldn’t have predicted, then there was no opportunity for intervention.\n",
    "\n",
    "We also have 195 (14%) False Positives where we will lose money because the promotion offered to these customers will just be an extra cost.\n",
    "\n",
    "596 (42%) are True Negatives (good customers) and 68 (5%) are False Negative (this is a missed opportunity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a churn model, often the reward of true positives is way different than the cost of false positives. Let’s use the following assumptions:\n",
    "\n",
    "- \\$500 voucher will be offered to all the customers identified as churn (True Positive + False Positive);\n",
    "- If we are able to stop the churn, we will gain $7500 in customer lifetime value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Description                    | Customers | Value | Total     |\n",
    "|--------------------------------|-----------|-------|-----------|\n",
    "| True Positive                  | 211       | 7500  | 1,582,000 |\n",
    "| True Positive + False Positive | 406       | 500   | -203,000  |\n",
    "|                                |           |       | **1,379,000** |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. GBM with H2O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators import *\n",
    "from h2o.grid import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = dataset.split_frame([0.7, 0.15], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify predictors and response\n",
    "x = train.columns\n",
    "y = \"Churn\"\n",
    "x.remove(y)\n",
    "\n",
    "# For binary classification, response should be a factor\n",
    "train[y] = train[y].asfactor()\n",
    "test[y] = test[y].asfactor()\n",
    "valid[y] = valid[y].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = H2OGradientBoostingEstimator(seed = 42, \n",
    "                                   model_id = 'default_gbm')\n",
    "\n",
    "%time gbm.train(x = x, y = y, training_frame = train, validation_frame = valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm.predict(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_gbm_per = gbm.model_performance(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_gbm_per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter estimation\n",
    "\n",
    "gbm = H2OGradientBoostingEstimator(ntrees = 500,\n",
    "                                   learn_rate = 0.05,\n",
    "                                   seed = 42,\n",
    "                                   model_id = 'grid_gbm')\n",
    "\n",
    "hyper_params_tune = {'max_depth' : [4, 5, 6, 7, 8],\n",
    "                     'sample_rate': [x/100. for x in range(20,101)],\n",
    "                     'col_sample_rate' : [x/100. for x in range(20,101)],\n",
    "                     'col_sample_rate_per_tree': [x/100. for x in range(20,101)],\n",
    "                     'col_sample_rate_change_per_level': [x/100. for x in range(90,111)]}\n",
    "\n",
    "search_criteria_tune = {'strategy': \"RandomDiscrete\",\n",
    "                        'max_runtime_secs': 900,  \n",
    "                        'max_models': 100,  ## build no more than 100 models\n",
    "                        'seed' : 42}\n",
    "\n",
    "random_grid = H2OGridSearch(model = gbm, hyper_params = hyper_params_tune,\n",
    "                            grid_id = 'random_grid',\n",
    "                            search_criteria = search_criteria_tune)\n",
    "\n",
    "%time random_grid.train(x = x, y = y, training_frame = train, validation_frame = valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_random_search = random_grid.get_grid(sort_by = 'auc',decreasing = True)\n",
    "sorted_random_search.sorted_metric_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_gbm = sorted_random_search.models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_gbm_per = tuned_gbm.model_performance(test)\n",
    "print(tuned_gbm_per.auc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_gbm.explain(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuned_gbm.explain_row(test, row_index=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
