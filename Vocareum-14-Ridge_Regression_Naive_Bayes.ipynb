{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment Overview\n",
    "This assignment will test your ability to code your own version of ridge-regularized regression in Python. Ridge Regression offers a way to mitigate some of the weaknesses of Least Squares Linear Regression to build more robust models. This assignment draws upon and presupposes the knowledge found in the lectures for Module 13.\n",
    "\n",
    "The assignment also builds upon the work performed in the module 13 assignment \"Linear Regression - Least Squares\". The data used will be the same. Though the last assignment tested your ability to read data into Pandas from a .csv. Those fundamental processes will not be directly tested here.\n",
    "\n",
    "This assignment is designed to build your familiarity and comfort coding in Python while also helping you review key topics from each module. As you progress through the assignment, answers will get increasingly complex. It is important that you adopt a data scientist's mindset when completing this assignment. Remember to run your code from each cell before submitting your assignment. Running your code beforehand will notify you of errors and give you a chance to fix your errors before submitting. You should view your Vocareum submission as if you are delivering a final project to your manager or client.\n",
    "\n",
    "Vocareum Tips\n",
    "\n",
    "Do not add arguments or options to functions unless you are specifically asked to. This will cause an error in Vocareum.\n",
    "Do not use a library unless you are expicitly asked to in the question.\n",
    "You can download the Grading Report after submitting the assignment. This will include feedback and hints on incorrect questions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge Regression and Bayesian Methods\n",
    "For this assignment, we will use a regression model on a housing price dataset to predict the price of a house based on its living area above the ground. More information about this dataset can be found here.\n",
    "\n",
    "Before coding an algorithm, we will take a look at our data using Python's pandas. For visualizations, we'll use matplotlib. Let's import the necessary libraries and load the datasets by using the pandas pd.read_csv() function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import the necessary modules\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (20.0, 10.0)  \n",
    "\n",
    "### Read in the data\n",
    "tr_path = 'data/train.csv'\n",
    "\n",
    "data = pd.read_csv(tr_path)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by performing some basic exploratory data analysis by using the function head() and the attribute columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1:\n",
    "5 points\n",
    "\n",
    "Which column has the most \"null\" values? Assign name of the column as string to ans1a. How many nulls are in that column? Assign number as int to ans1b.\n",
    "\n",
    "NOTE: To find the column that has the higher number of null values, use the idxmin() function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "ans1a = None\n",
    "ans1b = None\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "ans1a = data.count().idxmin()\n",
    "ans1b = 1453\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's plot the relationship between our variables of interest: the price for each house and the above ground living area in square feet.\n",
    "\n",
    "We can do so by creating a scatter plot using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot('GrLivArea', 'SalePrice', kind = 'scatter', marker = 'x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2:\n",
    "5 points\n",
    "\n",
    "Create a subset of our dataframe below containing only the \"Street\" and \"Alley\" columns from the data. Assign the new dataframe to 'ans2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "ans2 = None\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "cols = ['Street','Alley']\n",
    "ans2 = data[cols]\n",
    "### END SOLUTION\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coding Ridge Regression\n",
    "Preprocessing\n",
    "Before implementing ridge regression, it is important to mean-center our target variable and mean-center and standardize observations. We will do this by using the following formulas:\n",
    "\n",
    "Mean Center Target\n",
    "ycent=y0−y¯\n",
    " \n",
    "Standardize Observations\n",
    "Xstd=X0−X¯sX\n",
    " \n",
    "Where  X¯  is the sample mean of X and  sX  is the sample standard deviation of X.\n",
    "\n",
    "NOTE: The sample standard deviation should be calculated with 0 \"Delta Degrees of Freedom\"\n",
    "\n",
    "Back to top\n",
    "\n",
    "Question 3:\n",
    "5 points\n",
    "\n",
    "Why are the centering/standardization transformations described above important for ridge regression?\n",
    "\n",
    "a) Regression works best when values are unitless\n",
    "b) The transformations makes the regression more interpretable\n",
    "c) Ridge penalizes large coefficients; the transformations make the coefficients of similar scales\n",
    "d) It isn't important\n",
    "Assign character associated with your choice as a string to ans3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "ans3 = None\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "ans3 = 'c'\n",
    "### END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4:\n",
    "10 points\n",
    "\n",
    "Standardized values can be calculated using the following formula:\n",
    "\n",
    "Xstd=X0−X¯sX.\n",
    " \n",
    "Define a function \"standardize\" that accepts, as input a list of numbers and returns a list where those values have been standardized. Please use the NumPy function std() for calculating standard deviation\n",
    "\n",
    "NOTE: The sample standard deviation should be calculated with 0 \"Delta Degrees of Freedom\".\n",
    "If your answer does not match the example answer, check the default degrees of freedom in your standard deviation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "def standardize( num_list):\n",
    "    \"\"\"\n",
    "    Standardize the given list of numbers\n",
    "    \n",
    "    Positional arguments:\n",
    "        num_list -- a list of numbers\n",
    "    \n",
    "    Example:\n",
    "        num_list = [1,2,3,3,4,4,5,5,5,5,5]\n",
    "        nl_std = standardize(num_list)\n",
    "        print(np.round(nl_std,2))\n",
    "        #--> np.array([-2.11, -1.36, -0.61, -0.61,  \n",
    "                0.14,  0.14,  0.88,  0.88,  0.88,\n",
    "                0.88,  0.88])\n",
    "    \n",
    "    NOTE: the sample standard deviation should be calculated with 0 \"Delta Degrees of Freedom\"\n",
    "    \"\"\"\n",
    "    \n",
    "    return \n",
    "\n",
    "### BEGIN SOLUTION\n",
    "def standardize(num_list):\n",
    "    \n",
    "    # Calculate standard deviation and mean\n",
    "    std = np.std(num_list)\n",
    "    mean = np.mean(num_list)\n",
    "    \n",
    "    # Implement equation\n",
    "    toRet = [(x-mean)/std for x in num_list]\n",
    "    \n",
    "    return toRet\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will create a function which will preprocess our data by performing:\n",
    "\n",
    "mean subtraction from  y ,\n",
    "dimension standardization for  x .\n",
    "The formulas to Mean Center Target and Standardize Observations are given above.\n",
    "\n",
    "NOTE: The sample standard deviation should be calculated with 0 \"Delta Degrees of Freedom\"\n",
    "If your answer does not match the example answer, check the default degrees of freedom in your standard deviation function.\n",
    "\n",
    "Back to top\n",
    "\n",
    "Question 5:\n",
    "10 points\n",
    "\n",
    "Code a function called \"preprocess_for_regularization\" that accepts, as input, the DataFrame, a y_column_name input and an x_column_names input input Your function should preprocess our data by performing:\n",
    "\n",
    "mean subtraction from  y ,\n",
    "dimension standardization for  x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### YOUR ANSWER BELOW\n",
    "def preprocess_for_regularization(data, y_column_name, x_column_names):\n",
    "    \"\"\"\n",
    "    Perform mean subtraction and dimension standardization on data\n",
    "        \n",
    "    Positional argument:\n",
    "        data -- a pandas dataframe of the data to pre-process\n",
    "        y_column_name -- the name (string) of the column that contains\n",
    "            the target of the training data.\n",
    "        x_column_names -- a *list* of the names of columns that contain the\n",
    "            observations to be standardized\n",
    "        \n",
    "    Returns:\n",
    "        Return a DataFrame consisting only of the columns included\n",
    "        in `y_column_name` and `x_column_names`.\n",
    "        Where the y_column has been mean-centered, and the\n",
    "        x_columns have been mean-centered/standardized.\n",
    "        \n",
    "        \n",
    "    Example:\n",
    "        data = pd.read_csv(tr_path).head()\n",
    "        prepro_data = preprocess_for_regularization(data,'SalePrice', ['GrLivArea','YearBuilt'])\n",
    "        \n",
    "        print(prepro_data) #-->\n",
    "                   GrLivArea  YearBuilt  SalePrice\n",
    "                0  -0.082772   0.716753     7800.0\n",
    "                1  -1.590161  -0.089594   -19200.0\n",
    "                2   0.172946   0.657024    22800.0\n",
    "                3  -0.059219  -1.911342   -60700.0\n",
    "                4   1.559205   0.627159    49300.0\n",
    "    \n",
    "    NOTE: The sample standard deviation should be calculated with 0 \"Delta Degrees of Freedom\"\n",
    "    \n",
    "    If your answer does not match the example answer,\n",
    "    check the default degrees of freedom in your standard deviation function.\n",
    "    \"\"\"\n",
    "    return \n",
    "\n",
    "### BEGIN SOLUTION\n",
    "def preprocess_for_regularization(data, y_column_name, x_column_names):\n",
    "    \n",
    "    # Create list of all columns\n",
    "    toRetCol = x_column_names + [y_column_name]\n",
    "    \n",
    "    # subset dataframe\n",
    "    toRet = data[toRetCol].copy() # For \"setting with copy\" warning\n",
    "    \n",
    "    # calculate mean of y, then subtract from all y's\n",
    "    y_mean = np.mean(data[y_column_name])\n",
    "    toRet[y_column_name] = data[y_column_name].apply(lambda x: x - y_mean)\n",
    "\n",
    "    # Calc mean and std for every column in x\n",
    "    # Then apply standardization\n",
    "    for column in x_column_names:\n",
    "        mean = np.mean(data[column])\n",
    "        #std = data[column].std(ddof = 0)\n",
    "        std = np.std(data[column])\n",
    "        \n",
    "        toRet[column] = data[column].apply(lambda x: (x - mean)/std)\n",
    "    \n",
    "    return toRet\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you'll implement the equation for ridge regression using the closed form equation:\n",
    "\n",
    "wRR=(λ+XTX)−1XTy\n",
    " \n",
    "The function will be very similar to the function you wrote for Least Squares Regression with a slightly different matrix to invert.\n",
    "\n",
    "NB: Many numpy matrix functions will be useful. e.g. np.matmul, np.linalg.inv, np.ones, np.transpose, and np.identity.\n",
    "\n",
    "The main change from Least Squares Regression is that  λ  is a parameter we must set. This is different from the  w  parameters that we calculate from either closed form or approximation algorithms.\n",
    "\n",
    "We will address tuning parameters such as  λ  in the next section.\n",
    "\n",
    "Back to top\n",
    "\n",
    "Question 6:\n",
    "10 points\n",
    "\n",
    "Code a function called \"ridge_regression_weights\" that takes, as input, three inputs: two matricies corresponding to the x inputs and y target and a number (int or float) for the lambda parameter\n",
    "\n",
    "Your function should return a numpy array of regression weights\n",
    "\n",
    "The following steps must be accomplished:\n",
    "\n",
    "Ensure the number of rows of each the X matrix is greater than the number of columns. If not, transpose the matrix. Ultimately, the y input will have length n. Thus the x input should be in the shape n-by-p\n",
    "\n",
    "Prepend an n-by-1 column of ones to the input_x matrix\n",
    "\n",
    "Use the above equation to calculate the least squares weights. This will involve creating the lambda matrix - a p+1-by-p+1 matrix with the \"lambda_param\" on the diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "def ridge_regression_weights(input_x, output_y, lambda_param):\n",
    "    \"\"\"Calculate ridge regression least squares weights.\n",
    "    \n",
    "    Positional arguments:\n",
    "        input_x -- 2-d matrix of input data\n",
    "        output_y -- 1-d numpy array of target values\n",
    "        lambda_param -- lambda parameter that controls how heavily\n",
    "            to penalize large weight values\n",
    "        \n",
    "    Example:\n",
    "        training_y = np.array([208500, 181500, 223500, \n",
    "                                140000, 250000, 143000, \n",
    "                                307000, 200000, 129900, \n",
    "                                118000])\n",
    "                                \n",
    "        training_x = np.array([[1710, 1262, 1786, \n",
    "                                1717, 2198, 1362, \n",
    "                                1694, 2090, 1774, \n",
    "                                1077], \n",
    "                               [2003, 1976, 2001, \n",
    "                                1915, 2000, 1993, \n",
    "                                2004, 1973, 1931, \n",
    "                                1939]])\n",
    "        lambda_param = 10\n",
    "        \n",
    "        rrw = ridge_regression_weights(training_x, training_y, lambda_param)\n",
    "        \n",
    "        print(rrw) #--> np.array([-576.67947107,   77.45913349,   31.50189177])\n",
    "        print(rrw[2]) #--> 31.50189177\n",
    "        \n",
    "    Assumptions:\n",
    "        -- output_y is a vector whose length is the same as the\n",
    "        number of observations in input_x\n",
    "        -- lambda_param has a value greater than 0\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = np.array([])\n",
    "    return weights\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "def ridge_regression_weights(input_x, output_y, lambda_param):\n",
    "    \n",
    "    # Check to ensure dataframe is long not wide\n",
    "    if input_x.shape[0] < input_x.shape[1]:\n",
    "        input_x = np.transpose(input_x)\n",
    "    \n",
    "    # Create column of ones\n",
    "    ones = np.ones((len(output_y), 1), dtype=int)\n",
    "    \n",
    "    # Add column of ones to X\n",
    "    augmented_x = np.concatenate((ones, input_x), axis=1)\n",
    "    \n",
    "    # Create square lambda_matrix, with size equal to number of columns in X\n",
    "    lambda_matrix = lambda_param * np.identity(min(augmented_x.shape))\n",
    "    \n",
    "    # Invert lambda + dot-prod of x and transposed x\n",
    "    inv = np.linalg.inv(lambda_matrix + np.matmul(np.transpose(augmented_x), augmented_x))\n",
    "    \n",
    "    # dot-prod of inverted matrix and transposed X\n",
    "    left_multiplier = np.matmul(inv , np.transpose(augmented_x))\n",
    "    \n",
    "    # final dot-prod with the ys\n",
    "    weights = np.matmul(left_multiplier, output_y)\n",
    "    \n",
    "    return weights\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting the  λ  parameter\n",
    "For our final function before looking at the sklearn implementation of ridge regression, we will create a hyperparameter tuning algorithm.\n",
    "\n",
    "In ridge regression, we must pick a value for  λ . We have some intuition about  λ  from the equations that define it: small values tend to emulate the results from Least Squares, while large values will reduce the dimensionality of the problem. But the choice of  λ  can be motivated with a more precise quantitative treatment.\n",
    "\n",
    "Eventually, we will look to choose the value of  λ  that minimizes the validation error, which we will determine using  k -fold cross-validation.\n",
    "\n",
    "For this example, we will solve a simpler problem on finding a value that minimizes the list returned by the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Example of hiden function below:\n",
    "\n",
    "### `hidden` takes a single number as a parameter (int or float) and returns a list of 1000 numbers\n",
    "### the input must be between 0 and 50 exclusive\n",
    "\n",
    "def hidden(hp):\n",
    "    if (hp<=0) or (hp >= 50):\n",
    "        print(\"input out of bounds\")\n",
    "    \n",
    "    nums = np.logspace(0,5,num = 1000)\n",
    "    vals = nums** 43.123985172351235134687934\n",
    "    \n",
    "    user_vals = nums** hp\n",
    "    \n",
    "    return vals-user_vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "def minimize( passed_func):\n",
    "    \"\"\"\n",
    "    Find the numeric value that makes the mean of the\n",
    "    output array returned from 'passed_func' as close to 0 as possible.\n",
    "    \n",
    "    Positional Argument:\n",
    "        passed_func -- a function that takes a single number (between 0 and 50 exclusive)\n",
    "            as input, and returns a list of 1000 floats.\n",
    "        \n",
    "    Example:\n",
    "        passed_func = hidden\n",
    "        min_hidden = minimize(passed_func)\n",
    "        print(round(min_hidden,4))\n",
    "        #--> 43.1204 (answers will vary slightly, must be close to 43.123985172351)\n",
    "    \n",
    "    \"\"\"\n",
    "    # Create values to test\n",
    "    test_vals = ...\n",
    "    \n",
    "    # Find mean of returned array from function\n",
    "    ret_vals = ...\n",
    "    \n",
    "    # Find smallest mean\n",
    "    min_mean = ...\n",
    "    \n",
    "    # Return the test value that creates the smallest mean\n",
    "    return ...\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "def minimize(passed_func):\n",
    "    \n",
    "    # Create values to test\n",
    "    test_vals = list(np.linspace(.1,49.9, 1000))\n",
    "    \n",
    "    # Find mean of returned array from function\n",
    "    ret_vals = [abs(np.mean(passed_func(x))) for x in test_vals]\n",
    "    \n",
    "    # Find smallest mean\n",
    "    min_mean = min(ret_vals)\n",
    "    \n",
    "    # Return the test value that creates the smallest mean\n",
    "    return test_vals[ret_vals.index(min_mean)]\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above simulates hyperparameter tuning.\n",
    "\n",
    "In the case of ridge regression, you would be searching lambda parameters to minimize the validation error.\n",
    "\n",
    "The hidden function would be analogous to the model building, the returned list would be analogous to the residuals, and the mean of that list would be analogous to the validation error.\n",
    "\n",
    "See below for an example of using the functions built above that automatically perform hyperparameter tuning using mean absolute deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda_search_func(lambda_param):\n",
    "    \n",
    "    # Define X and y\n",
    "    # with preprocessing\n",
    "    df = preprocess_for_regularization(data.head(50),'SalePrice', ['GrLivArea','YearBuilt'])\n",
    "    \n",
    "    y_true = df['SalePrice'].values\n",
    "    X = df[['GrLivArea','YearBuilt']].values\n",
    "    \n",
    "    # Calculate Weights then use for predictions\n",
    "    weights = ridge_regression_weights(X, y_true, lambda_param )\n",
    "    y_pred = weights[0] + np.matmul(X,weights[1:])\n",
    "    \n",
    "    # Calculate Residuals\n",
    "    resid = y_true - y_pred\n",
    "    \n",
    "    # take absolute value to tune on mean-absolute-deviation\n",
    "    # Alternatively, could use:\n",
    "    # return resid **2-S\n",
    "    # for tuning on mean-squared-error\n",
    "    \n",
    "    return abs(resid)\n",
    "\n",
    "minimize(lambda_search_func)    # --> about 2.9414414414414414"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 8:\n",
    "5 points\n",
    "\n",
    "Why is cross-validation useful?\n",
    "\n",
    "a) to minimize the liklihood of overfitting\n",
    "b) Cross-validation allows us to fit on all our data\n",
    "c) cross-validation standardizes outputs\n",
    "d) cross-validation is not useful\n",
    "Assing the character associated with your choice as a string to ans1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "ans1 = None\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "ans1 = 'a'\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge Regression in sklearn\n",
    "In the next question, we will ask you to implement Ridge regression in sklearn.\n",
    "\n",
    "Back to top\n",
    "\n",
    "Question 9:\n",
    "10 points\n",
    "\n",
    "Use the function LinearRegression from sklearn to instantiate the classifier lr. Use the function Ridge from sklear to instantiate the classifier reg. For this classifier, set the parameter alpha=100000. Use the Ridge function to instantiate another classifier, reg0, but, this time, set alpha=0.\n",
    "\n",
    "Define a for loop with two indices, m and name. m will run over the three classifiers just defined and name will run over the list [\"LeastSquares\",\"Ridge alpha = 100000\",\"Ridge, alpha = 0\"]. In each iteration of your fol loop, you should fit the \"X\" ('GrLivArea' and 'YearBuilt') and the \"y\" ('SalePrice') from data.\n",
    "\n",
    "Complete your for loop with the following print statement: print(name, \"Intercept:\", m.intercept_, \"Coefs:\",m.coef_,\"\\n\")\n",
    "\n",
    "NOTE: Note, the \"alpha\" parameter defines regularization strength. Lambda is a reserved word in Python -- Thus \"alpha\" instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GRADED\n",
    "\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "lr = None\n",
    "reg = None\n",
    "reg0 = None\n",
    "### BEGIN SOLUTION\n",
    "### An alpha of 0 is equivalent to least-squares regression\n",
    "lr = LinearRegression()\n",
    "reg = Ridge(alpha = 100000)\n",
    "reg0 = Ridge(alpha = 0)\n",
    "\n",
    "# Notice how the consistent sklearn syntax may be used to easily fit many kinds of models\n",
    "for m, name in zip([lr, reg, reg0], [\"LeastSquares\",\"Ridge alpha = 100000\",\"Ridge, alpha = 0\"]):\n",
    "    \n",
    "    m.fit(data[['GrLivArea','YearBuilt']], data['SalePrice'])\n",
    "    print(name, \"Intercept:\", m.intercept_, \"Coefs:\",m.coef_,\"\\n\")\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note in the above example, an alpha of 100,000 is set for the ridge regularization. The reason an alpha value this high is required is because standardization/mean centering of our inputs did not occur, and instead of working with inputs on the order of [-4,4] we are on the interval of [0,2000].\n",
    "\n",
    "Back to top\n",
    "\n",
    "Question 10:\n",
    "5 points\n",
    "\n",
    "Above, the coefficent around 95/96 corresponds with:\n",
    "\n",
    "a) Living Area\n",
    "b) Year Built\n",
    "c) Sale Price Assign character associated with your choice as string to ans2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "ans2 = None\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "ans2 = 'a'\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 11:\n",
    "5 points\n",
    "\n",
    "True or False:\n",
    "\n",
    "A larger \"alpha\" corresponds to a greater amount of regularization\n",
    "\n",
    "Assign boolean choice to ans3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "ans3 = None\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "ans3 = True\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
